{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Source:\n",
    "- <a href=\"https://www.kaggle.com/datasets/oddrationale/mnist-in-csv/data\">DARIEL DATO-ON -MNIST in CSV\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/oddrationale/mnist-in-csv/versions/\n",
      "Dataset URL: https://www.kaggle.com/datasets/oddrationale/mnist-in-csv/versions/\n"
     ]
    }
   ],
   "source": [
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "files = [\"mnist_train.csv\", \"mnist_test.csv\"]\n",
    "\n",
    "os.mkdir(\"data\")\n",
    "\n",
    "for file in files:\n",
    "    file_base = file.split(\".\")[0]\n",
    "\n",
    "    api.dataset_download_file(\n",
    "        dataset = \"oddrationale/mnist-in-csv/\",\n",
    "        file_name = file,\n",
    "        path = f\"data/{file}\"\n",
    "    )\n",
    "\n",
    "    os.rename(f\"data/{file}\", f\"data/{file_base}\")\n",
    "\n",
    "    with zipfile.ZipFile(f\"data/{file_base}/{file}.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")\n",
    "\n",
    "    os.remove(f\"data/{file_base}/{file}.zip\")\n",
    "    os.rmdir(f\"data/{file_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./data/mnist_train.csv\").to_numpy()\n",
    "X_train = data_train[:, 1:] / 255.0\n",
    "y_train = data_train[:, 0]\n",
    "\n",
    "data_test = pd.read_csv(\"./data/mnist_test.csv\").to_numpy()\n",
    "X_test = data_test[:, 1:] / 255.0\n",
    "y_test = data_test[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Sources:\n",
    "- <a href=\"https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\">3Blue1Brown</a>\n",
    "- <a href=\"https://www.youtube.com/watch?v=w8yWXqWQYmU\">Samson Zhang - Building a neural network FROM SCRATCH</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, lr:float=0.01, n_iters:int=1000):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "        self.n_samples = None\n",
    "        self.n_features = None\n",
    "\n",
    "    def _init_params(self):\n",
    "        self.W1 = np.random.rand(10, self.n_features) - 0.5\n",
    "        self.b1 = np.random.rand(10, 1) - 0.5\n",
    "        self.W2 = np.random.rand(10, 10) - 0.5\n",
    "        self.b2 = np.random.rand(10, 1) - 0.5\n",
    "\n",
    "    def _ReLU(self, Z):\n",
    "        return np.maximum(Z, 0)\n",
    "    \n",
    "    def _ReLU_deriv(self, Z):\n",
    "        return Z > 0\n",
    "    \n",
    "    def _softmax(self, Z):\n",
    "        return np.exp(Z) / sum(np.exp(Z))\n",
    "    \n",
    "    def _one_hot(self, Y):\n",
    "        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "        one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "        one_hot_Y = one_hot_Y.T\n",
    "        return one_hot_Y\n",
    "    \n",
    "    def _forward_prop(self, X):\n",
    "        Z1 = self.W1.dot(X) + self.b1\n",
    "        A1 = self._ReLU(Z1)\n",
    "        Z2 = self.W2.dot(A1) + self.b2\n",
    "        A2 = self._softmax(Z2)\n",
    "        return Z1, A1, Z2, A2\n",
    "\n",
    "    def _backward_prop(self, Z1, A1, Z2, A2, X, Y):\n",
    "        one_hot_Y = self._one_hot(Y)\n",
    "        dZ2 = A2 - one_hot_Y\n",
    "        dW2 = 1 / self.n_samples * dZ2.dot(A1.T)\n",
    "        db2 = 1 / self.n_samples * np.sum(dZ2)\n",
    "        dZ1 = self.W2.T.dot(dZ2) * self._ReLU_deriv(Z1)\n",
    "        dW1 = 1 / self.n_samples * dZ1.dot(X.T)\n",
    "        db1 = 1 / self.n_samples * np.sum(dZ1)\n",
    "        return dW1, db1, dW2, db2\n",
    "    \n",
    "    def _update_params(self, dW1, db1, dW2, db2):\n",
    "        self.W1 = self.W1 - self.lr * dW1\n",
    "        self.b1 = self.b1 - self.lr * db1\n",
    "        self.W2 = self.W2 - self.lr * dW2\n",
    "        self.b2 = self.b2 - self.lr * db2\n",
    "\n",
    "    def _get_predictions(self, A2):\n",
    "        return np.argmax(A2, 0)\n",
    "\n",
    "    def _get_accuracy(self, y_real, y_pred):\n",
    "        return np.sum(y_real == y_pred) / y_real.size\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self._init_params()\n",
    "\n",
    "        X = X.T\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            Z1, A1, Z2, A2 = self._forward_prop(X)\n",
    "            dW1, db1, dW2, db2 = self._backward_prop(Z1, A1, Z2, A2, X, Y)\n",
    "            self._update_params(dW1, db1, dW2, db2)\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: {}  |  Accuracy: {:.2f}%\".format(\n",
    "                    i+1,\n",
    "                    self._get_accuracy(self._get_predictions(A2), Y) * 100\n",
    "                ), end=\"\\r\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        _, _, _, A2 = self._forward_prop(X.T)\n",
    "        predictions = self._get_predictions(A2)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000  |  Accuracy: 87.99%\r"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(0.1, 1000)\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.37\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = nn.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}\".format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
